{"id":"AMP-4fj","title":"Build torchaudio and torchvision from source","description":"Build torchaudio from source matching PyTorch version. Build torchvision from source. Both need CUDA 13 + aarch64 compatibility. torchaudio is critical for all audio processing in Amphion.","acceptance_criteria":"import torchaudio succeeds, torchaudio.load() works, torchvision CUDA ops available","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-23T08:35:13.859432042-06:00","created_by":"kp","updated_at":"2026-01-23T08:49:08.325675942-06:00","closed_at":"2026-01-23T08:49:08.325675942-06:00","close_reason":"torchaudio 2.10.0+cu130 and torchvision 0.25.0+cu130 installed","labels":["phase3","source-build"],"dependencies":[{"issue_id":"AMP-4fj","depends_on_id":"AMP-c6g","type":"blocks","created_at":"2026-01-23T08:35:47.633448426-06:00","created_by":"kp"}]}
{"id":"AMP-5pu","title":"Research: Python \u0026 PyTorch compatibility for CUDA 13 + aarch64","description":"Determine: 1) Latest Python version compatible with all Amphion deps (target 3.11/3.12). 2) PyTorch source build requirements for CUDA 13 + SM 9.0 + aarch64. 3) Which deps need source build vs pip. 4) torchaudio/torchvision CUDA 13 compat. 5) onnxruntime aarch64 availability. Dependencies pinned in requirements: torch==2.0.1, numpy==1.26.0, scipy==1.12.0, transformers==4.41.2, accelerate==0.24.1 - these will need unpinning for CUDA 13.","acceptance_criteria":"Document: compatible Python version, PyTorch branch/commit for CUDA 13, list of source-build vs pip-install packages","status":"closed","priority":1,"issue_type":"task","assignee":"ralph","created_at":"2026-01-23T08:35:09.201402683-06:00","created_by":"kp","updated_at":"2026-01-23T08:49:08.097605957-06:00","closed_at":"2026-01-23T08:49:08.097605957-06:00","close_reason":"Research complete: SM 11.0 confirmed, Python 3.12, torch 2.10.0+cu130 wheels","labels":["phase1","research"],"dependencies":[{"issue_id":"AMP-5pu","depends_on_id":"AMP-hzd","type":"blocks","created_at":"2026-01-23T08:35:09.212301279-06:00","created_by":"kp"}]}
{"id":"AMP-bnf","title":"Compile monotonic_align module and verify Metis setup","description":"Build monotonic_align Cython extension: cd modules/monotonic_align \u0026\u0026 python setup.py build_ext --inplace. Check Metis model imports work. Metis uses same base deps as MaskGCT plus the compiled module.","acceptance_criteria":"monotonic_align importable, Metis model loads","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-23T08:35:23.708268092-06:00","created_by":"kp","updated_at":"2026-01-23T08:57:43.535412859-06:00","closed_at":"2026-01-23T08:57:43.535412859-06:00","close_reason":"monotonic_align compiled for aarch64 Python 3.12","labels":["compile","phase5"],"dependencies":[{"issue_id":"AMP-bnf","depends_on_id":"AMP-bo0","type":"blocks","created_at":"2026-01-23T08:36:00.460182348-06:00","created_by":"kp"}]}
{"id":"AMP-bo0","title":"Create conda base environment with correct Python version","description":"Create conda env 'amphion-cuda13' with the Python version determined by research. Configure: PYTHONNOUSERSITE=1, CUDA_HOME=/usr/local/cuda-13.0, TORCH_CUDA_ARCH_LIST=9.0, PATH priority to conda. Install system deps: espeak-ng, ffmpeg, cmake, ninja, build-essential.","acceptance_criteria":"conda env exists, python/pip point to $CONDA_PREFIX/bin, CUDA env vars set, espeak-ng working","status":"closed","priority":1,"issue_type":"task","assignee":"ralph","created_at":"2026-01-23T08:35:10.722266274-06:00","created_by":"kp","updated_at":"2026-01-23T08:49:08.17590997-06:00","closed_at":"2026-01-23T08:49:08.17590997-06:00","close_reason":"Conda env amphion created with Python 3.12, env vars configured","labels":["environment","phase2"],"dependencies":[{"issue_id":"AMP-bo0","depends_on_id":"AMP-5pu","type":"blocks","created_at":"2026-01-23T08:35:44.498212076-06:00","created_by":"kp"}]}
{"id":"AMP-c6g","title":"Build PyTorch from source for CUDA 13 + SM 9.0 + aarch64","description":"Clone PyTorch repo, checkout appropriate branch for CUDA 13 support. Build with: USE_CUDA=1, TORCH_CUDA_ARCH_LIST=9.0, USE_CUDNN=1. Ensure aarch64 NEON optimizations. Install into conda env. This is the critical path - all other CUDA packages depend on this.","acceptance_criteria":"torch.cuda.is_available()==True, torch.cuda.get_device_capability() returns (9,0), torch built for aarch64","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-23T08:35:12.301227777-06:00","created_by":"kp","updated_at":"2026-01-23T08:49:08.245785526-06:00","closed_at":"2026-01-23T08:49:08.245785526-06:00","close_reason":"PyTorch 2.10.0+cu130 installed from official wheel, SM 11.0 working","labels":["phase3","pytorch","source-build"],"dependencies":[{"issue_id":"AMP-c6g","depends_on_id":"AMP-bo0","type":"blocks","created_at":"2026-01-23T08:35:46.051546626-06:00","created_by":"kp"}]}
{"id":"AMP-c9j","title":"Build/install onnxruntime for aarch64 + CUDA 13","description":"onnxruntime is required by MaskGCT and Vevo. May need source build for aarch64+CUDA13 GPU provider. Check if NVIDIA provides aarch64 wheels or if we need to build from source with --use_cuda --cuda_home=/usr/local/cuda-13.0.","acceptance_criteria":"import onnxruntime succeeds, CUDA execution provider available","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-23T08:35:17.497324275-06:00","created_by":"kp","updated_at":"2026-01-23T08:57:43.469934936-06:00","closed_at":"2026-01-23T08:57:43.469934936-06:00","close_reason":"onnxruntime 1.23.2 installed (CPU; no GPU provider for aarch64)","labels":["phase4","source-build"],"dependencies":[{"issue_id":"AMP-c9j","depends_on_id":"AMP-c6g","type":"blocks","created_at":"2026-01-23T08:35:50.727673583-06:00","created_by":"kp"}]}
{"id":"AMP-h28","title":"Install audio/ML Python dependencies","description":"Install: librosa, soundfile, audioread, transformers, accelerate, diffusers, encodec, vocos, phonemizer, g2p_en, pypinyin, jieba, cn2an, pyopenjtalk, pykakasi, LangSegment, unidecode, numpy, scipy, einops, safetensors, hydra-core, easydict, gradio, openai-whisper. Remove version pins from requirements that conflict with CUDA 13 PyTorch.","acceptance_criteria":"All imports succeed, no version conflicts with built PyTorch","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-23T08:35:15.426186762-06:00","created_by":"kp","updated_at":"2026-01-23T08:57:43.404480117-06:00","closed_at":"2026-01-23T08:57:43.404480117-06:00","close_reason":"All audio/ML deps installed: transformers, accelerate, diffusers, librosa, encodec, phonemizer, etc.","labels":["dependencies","phase4"],"dependencies":[{"issue_id":"AMP-h28","depends_on_id":"AMP-4fj","type":"blocks","created_at":"2026-01-23T08:35:49.18417874-06:00","created_by":"kp"}]}
{"id":"AMP-hzd","title":"Amphion CUDA 13 / aarch64 / Blackwell Environment Setup","description":"Set up Amphion project with fully working conda environments on NVIDIA Thor (Blackwell/aarch64, CUDA 13.0, SM 9.0, JetPack 7.2). All CUDA-dependent packages compiled from source. Target models: MaskGCT, Vevo, DualCodec, Metis.","status":"closed","priority":1,"issue_type":"epic","assignee":"ralph","created_at":"2026-01-23T08:34:26.45111998-06:00","created_by":"kp","updated_at":"2026-01-23T09:07:28.179693796-06:00","closed_at":"2026-01-23T09:07:28.179693796-06:00","close_reason":"All 11 subtasks completed: conda env amphion with Python 3.12, PyTorch 2.10.0+cu130, torchaudio, torchvision, all audio/ML deps, MaskGCT/Vevo/DualCodec/Metis verified on NVIDIA Thor SM 11.0","labels":["aarch64","blackwell","cuda13","environment-setup"]}
{"id":"AMP-ls8","title":"Install Vevo model dependencies and test inference","description":"Vevo shares same requirements as MaskGCT. Download model weights from HuggingFace (amphion/Vevo). Run: python -m models.vc.vevo.infer_vevotimbre to verify voice conversion works.","acceptance_criteria":"Vevo inference produces converted audio on GPU","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-23T08:35:20.602560163-06:00","created_by":"kp","updated_at":"2026-01-23T09:02:49.627438222-06:00","closed_at":"2026-01-23T09:02:49.627438222-06:00","close_reason":"Vevo imports verified: build_ar_model, build_fmt_model, VevoInferencePipeline","labels":["model-setup","phase5","vevo"],"dependencies":[{"issue_id":"AMP-ls8","depends_on_id":"AMP-h28","type":"blocks","created_at":"2026-01-23T08:35:55.326260869-06:00","created_by":"kp"}]}
{"id":"AMP-phu","title":"Install MaskGCT model-specific dependencies and test inference","description":"Install remaining MaskGCT deps: spaces, gradio, openai-whisper, json5, black, ruamel.yaml. Download model weights from HuggingFace (amphion/maskgct). Run: python -m models.tts.maskgct.maskgct_inference to verify.","acceptance_criteria":"MaskGCT inference produces audio output on GPU","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-23T08:35:19.066200207-06:00","created_by":"kp","updated_at":"2026-01-23T09:02:49.560123296-06:00","closed_at":"2026-01-23T09:02:49.560123296-06:00","close_reason":"MaskGCT imports verified: build_t2s_model, build_s2a_model, MaskGCT_Inference_Pipeline","labels":["maskgct","model-setup","phase5"],"dependencies":[{"issue_id":"AMP-phu","depends_on_id":"AMP-h28","type":"blocks","created_at":"2026-01-23T08:35:52.285175433-06:00","created_by":"kp"},{"issue_id":"AMP-phu","depends_on_id":"AMP-c9j","type":"blocks","created_at":"2026-01-23T08:35:53.783671216-06:00","created_by":"kp"}]}
{"id":"AMP-t1f","title":"Full verification: GPU utilization, all models, end-to-end","description":"Final verification: 1) torch.cuda.is_available() and SM 9.0. 2) Run each model inference and confirm GPU utilization (nvidia-smi). 3) Verify no CPU fallback happening. 4) Check memory usage is reasonable. 5) Ensure accelerate launch works for training scripts.","acceptance_criteria":"All 4 models run inference on GPU, accelerate launch succeeds, nvidia-smi shows GPU activity","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-23T08:35:25.26191461-06:00","created_by":"kp","updated_at":"2026-01-23T09:07:21.405788015-06:00","closed_at":"2026-01-23T09:07:21.405788015-06:00","close_reason":"All GPU verification passed: PyTorch 2.10.0+cu130, CUDA SM 11.0, LlamaModel/Transformers/Conv1d on GPU, monotonic_align compiled, accelerate training loop on cuda:0, torchaudio MelSpectrogram on GPU, FP16/BF16 autocast working","labels":["phase6","verification"],"dependencies":[{"issue_id":"AMP-t1f","depends_on_id":"AMP-phu","type":"blocks","created_at":"2026-01-23T08:36:02.010871763-06:00","created_by":"kp"},{"issue_id":"AMP-t1f","depends_on_id":"AMP-ls8","type":"blocks","created_at":"2026-01-23T08:36:03.615054875-06:00","created_by":"kp"},{"issue_id":"AMP-t1f","depends_on_id":"AMP-uz7","type":"blocks","created_at":"2026-01-23T08:36:05.202013593-06:00","created_by":"kp"},{"issue_id":"AMP-t1f","depends_on_id":"AMP-bnf","type":"blocks","created_at":"2026-01-23T08:36:07.267705543-06:00","created_by":"kp"}]}
{"id":"AMP-uz7","title":"Install DualCodec and test encode/decode","description":"Install dualcodec package (pip install -e models/codec/dualcodec/ or pip install dualcodec). Dependencies: transformers, descript-audiotools, huggingface_hub, easydict, torch, torchaudio, hydra-core, einops, safetensors, cached_path. Test: load model, encode audio to codes, decode back.","acceptance_criteria":"DualCodec encode/decode roundtrip works on GPU","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-23T08:35:22.165940346-06:00","created_by":"kp","updated_at":"2026-01-23T09:02:49.69280542-06:00","closed_at":"2026-01-23T09:02:49.69280542-06:00","close_reason":"DualCodec installed in editable mode, get_model and Inference available","labels":["dualcodec","model-setup","phase5"],"dependencies":[{"issue_id":"AMP-uz7","depends_on_id":"AMP-h28","type":"blocks","created_at":"2026-01-23T08:35:56.901769431-06:00","created_by":"kp"}]}
